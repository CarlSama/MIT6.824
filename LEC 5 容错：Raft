总议题：使用状态机复制（SRM）的容错服务【客户端、备份集群】
例子：管理配置的服务器，例如MapReduce、GFS的主节点
例子：kv存储服务器，put()/get()
目标：就像单点无备份的服务器，但是能容忍一定数量的服务器异常
策略：每个备份服务器按照相同的顺序执行相同的命令
      保证按照执行的顺序实现备份，如果一个失败，其他的节点也能保证系统正常（一个失效时，客户端访问另一个服务器）
      GFS和VMware FT都有这个容错能力
      

主要的问题：如果避免脑裂？
    假设客户端可以访问备份A，无法访问备份B。客户端能只操作A而继续运行？
    如果B真的crash了，客户端必须继续运行，忽略B
    如果B还正在运行，只是客户端访问不到，也许客户端应该等待B的回应，因为B可能会服务于其他客户端 -- 导致脑裂


为什么脑裂为什么不行：
    容错的KV存储
    C1：put(k1, v1)
    C2: put(k1, v2)
    C1: get(k1) -> ??
    结果应该是V2，就像非复制服务器的效果。但是如果两个服务器读取的服务于C1和C2，C1会得到V1

困难：机器无法区分“crashed“和"partitioned"

我们需要状态机复制机制：
  任意点失效时保持可用
  处理分区w/o的脑裂问题
  如果失效过多：等待修理，然后恢复

处理w/ partition 的方法：多数投票
  2f + 1个服务器来容忍f个失效（例如，3个机器容忍1个故障）
  必须获取大部分（f+1)投票来继续处理，f个故障会剩余f+1机器，可以继续
  为什么大多数投票可以避免脑裂？最多1个分区能得到大多数投票（大多数指的是2f+1服务器的大多数，而是幸存者的大多数）
  大多数投票的最大优势是：任意机器都必须交互（相互交互的机器只能给一个投票，交互过程可以发现之前决定的信息）

在90年出现了两个分区容忍复制策略
  Paxos和View-Stamped复制
  这个技术在之后10年被广泛的使用
  
Raft总览
Raft的状态机复制
  【图表：客户端，3份复制，k/v层，raft层，日志】
  服务器的Raft层选leader
  客户端给leader的k/v层发送RPC（Put，Get，Append）
  leader的Raft层将客户端命令发送给每个备份机器，每个机器将命令添加到本地日志
  只有大部分（在下一次leader选举时会存在）将一个entry放入到自己的日志时，才被认为是committed
  一旦leader声明committed，服务器执行entry，k/v层给DB回复PUT，或者获取Get结果
  然后leader给客户端回复w/执行结果

为什么使用日志？
  服务保持状态机的状态（例如，k/v DB)
    为何还不够？
  给命令排序很重要：
    帮助备份机器按照相同的顺序执行
    确保leader和备份机器有相同的日志
  备份使用日志来存储命令
    知道主节点提交
    主节点在备份节点丢失信息时，可以重新发送
    节点重新启动后，回放来保持持久化

服务器的日志都是其他的精确复制吗？
  不：一些备份会延迟
  不：可能会短暂的包含不同内容
  好消息：
    最终会收拢，commit机制抱枕服务器只会执行稳定的内容

选主：

leader的职责：保证备份执行相同的命令，按照相同顺序

Raft指定leader的number
  新的leader -> 新的任期
  一个任期最多一个leader；也许不会有leader
  number帮助服务器跟随最新的leader，而非被取代的leader

合适重新选leader？
  其他服务器在“选举超时“时间内没从leader收到信息
  他们增加本地currentTerm，变为candidate，开始选举
  注意：这会导致无效的选举；虽然慢但是安全
  注意：旧的leader仍然存活，并且认为自己是主

    为何还不够？candi
